import base64
from typing import List, Optional
from openai import OpenAI
import openai
import os


def ask_about_images(
    input_prompt: str,
    local_images: Optional[List[str]] = None,
    url_images: Optional[List[str]] = None,
) -> str:
    """
    Generates a descriptive text response based on a question or instruction
    related to provided images using the OpenAI model.

    Parameters:
        input_prompt (str): The query or instruction related to the images.
        local_images (Optional[List[str]]): A list of file paths to local images.
            Example:
            [
                "/path/to/local_image1.jpg",
                "/path/to/local_image2.png"
            ]
        url_images (Optional[List[str]]): A list of URLs pointing to online images.
            Example:
            [
                "https://example.com/image1.jpg",
                "https://example.com/image2.png"
            ]

    Returns:
        str: A text response generated by the model based on the input prompt
             and the content of the images.


    Notes:
        - Local images are automatically read and encoded in base64 before sending.
        - Online images (URLs) are sent directly without downloading or encoding.
        - The model is best at answering general questions about what is present in the images. While it does understand the relationship between objects in images, it is not yet optimized to answer detailed questions about the location of certain objects in an image.
    """
    model = "gpt-4o-mini"

    # Initialize the OpenAI client if not provided
    client = OpenAI()

    def encode_image_to_base64(image_path: str) -> str:
        """
        Reads a local image file and encodes it in base64.

        Parameters:
            image_path (str): The file path to the local image.

        Returns:
            str: A base64-encoded string of the image in the format required by the API.
        """
        try:
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
            encoded_str = base64.b64encode(image_data).decode("utf-8")
            # Attempt to determine the MIME type based on file extension
            extension = os.path.splitext(image_path)[1].lower()
            mime_type = "jpeg"  # Default MIME type
            if extension in [".png"]:
                mime_type = "png"
            elif extension in [".gif"]:
                mime_type = "gif"
            elif extension in [".bmp"]:
                mime_type = "bmp"
            elif extension in [".webp"]:
                mime_type = "webp"
            return f"data:image/{mime_type};base64,{encoded_str}"
        except FileNotFoundError:
            raise FileNotFoundError(f"Local image not found at path: {image_path}")
        except Exception as e:
            raise IOError(f"Error reading local image at path {image_path}: {e}")

    # Build the message content starting with the text prompt
    message_content = [{"type": "text", "text": input_prompt}]

    # Process local images: encode them in base64
    if local_images:
        for img_path in local_images:
            encoded_image = encode_image_to_base64(img_path)
            message_content.append(
                {"type": "image_url", "image_url": {"url": encoded_image}}
            )

    # Process URL images: add them directly
    if url_images:
        for img_url in url_images:
            # Basic validation for URL format
            if not img_url.lower().startswith(("http://", "https://")):
                raise ValueError(f"Invalid URL format: {img_url}")
            message_content.append({"type": "image_url", "image_url": {"url": img_url}})

    if not (local_images or url_images):
        raise ValueError(
            "At least one image must be provided via 'local_images' or 'url_images'."
        )

    try:
        # Call the OpenAI API
        response = client.chat.completions.create(
            model=model, messages=[{"role": "user", "content": message_content}]
        )
        # Extract and return the response text
        return response.choices[0].message.content
    except openai.error.OpenAIError as e:
        raise RuntimeError(f"OpenAI API error: {e}")
    except Exception as e:
        raise RuntimeError(f"Failed to get response from OpenAI API: {e}")

GLOBAL_CNT = 4
EVALUATION_CNT = 0


def evaluate_image(image_path: str, requirements: str, query: str) -> str:
    """
    Generates a text response to the query using the OpenAI model, based on specified image and its expected requirements.

    Parameters:
        image_path (str): The file path to the local image.
            Example:
            "/path/to/local_image1.jpg"

        requirements (str): A string detailing the complete requirements that
                            the image is expected to fully satisfy.

        query (str): A specific question or instruction guiding the evaluation.
                            For example, it can ask whether the image meets certain criteria
                            or request feedback on specific aspects.

    Returns:
        str: a text response to the query based on
             the provided requirements and image.

    Raises:
        FileNotFoundError: If the image file does not exist at the specified path.
        IOError: If there is an error reading the image file.
        ValueError: If any of the input parameters are invalid.
        RuntimeError: If there is an issue with the OpenAI API request.
    Note:
        The `evaluate_image()` tool provides visual feedback that should be used as a reference only as it may not always be entirely accurate.
    """
    model = "gpt-4o-mini"

    # Initialize the OpenAI client if not provided
    # client = OpenAI()

    # 显式写入 API 密钥和 Base URL
    api_key = "sk-IhCvPiAG4gpA4rAcywj8suM79i4IeTE8zj44IdND4qgYftYZ"
    base_url = "https://api.openai-proxy.org/v1"
    client = OpenAI(api_key=api_key, base_url=base_url)

    global EVALUATION_CNT
    if EVALUATION_CNT >= GLOBAL_CNT:
        return "The `evaluate_image` tool has reached its maximum usage limit. Please assess the compliance of the plotting code with the requirements instead."

    def encode_image_to_base64(image_path: str) -> str:
        """
        Reads a local image file and encodes it in base64.

        Parameters:
            image_path (str): The file path to the local image.

        Returns:
            str: A base64-encoded string of the image in the format required by the API.
        """
        try:
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
            encoded_str = base64.b64encode(image_data).decode("utf-8")
            # Attempt to determine the MIME type based on file extension
            extension = os.path.splitext(image_path)[1].lower()
            mime_type = "jpeg"  # Default MIME type
            if extension in [".png"]:
                mime_type = "png"
            elif extension in [".gif"]:
                mime_type = "gif"
            elif extension in [".bmp"]:
                mime_type = "bmp"
            elif extension in [".webp"]:
                mime_type = "webp"
            return f"data:image/{mime_type};base64,{encoded_str}"
        except FileNotFoundError:
            raise FileNotFoundError(f"Local image not found at path: {image_path}")
        except Exception as e:
            raise IOError(f"Error reading local image at path {image_path}: {e}")

    # Validate input parameters
    if not image_path:
        raise ValueError("The 'image_path' parameter must be provided and non-empty.")
    if not os.path.isfile(image_path):
        raise FileNotFoundError(
            f"The image file does not exist at the specified path: {image_path}"
        )
    if not requirements:
        raise ValueError("The 'requirements' parameter must be provided and non-empty.")
    if not query:
        raise ValueError("The 'query' parameter must be provided and non-empty.")

    # Encode the local image to base64
    encoded_image = encode_image_to_base64(image_path)

    # Construct the message content for the OpenAI API
    # Combine the requirements and input_prompt into a single prompt
    combined_prompt = (
        f"Expected Requirements for the image:\n{requirements}\n\n"
        f"Based on the image and its expected requirements, answer the following question in detail. If the figure is blank, you should point it out clearly and immediately.\n"
        f"Query:\n{query}\n\n"
        f"Your response:\n"
    )
    print(combined_prompt)

    # Prepare the messages payload including the image
    message_content = [{"type": "text", "text": combined_prompt}]
    message_content.append({"type": "image_url", "image_url": {"url": encoded_image}})
    try:
        # Call the OpenAI API
        response = client.chat.completions.create(
            model=model, messages=[{"role": "user", "content": message_content}]
        )
        # Extract and return the response text
        EVALUATION_CNT += 1
        return response.choices[0].message.content
    except Exception as e:
        raise RuntimeError(f"Failed to get response from OpenAI API: {e}")


if __name__ == "__main__":
    res = ask_about_images(
        input_prompt="what is on the image?",
        local_images=["evaluation/DSBench/data/00000004/flow.jpg"],
    )

    print(res)

    """
    from vision_tool import ask_about_images
    import inspect
    signature = inspect.signature(ask_about_images)
    print(signature)
    print(ask_about_images.__doc__)
    """
